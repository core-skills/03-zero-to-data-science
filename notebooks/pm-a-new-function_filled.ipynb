{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Functions\n",
    "\n",
    "This exercise will lead you through taking some common data processing steps and wrapping them up into a reusable function.\n",
    "\n",
    "The function should import a file, do a bit of processing and formatting, output the processed data elsewhere and return the path to the processed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if using jupyterhub\n",
    "# %pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path # handy for working with file paths, consistent across systems (windows, mac, unix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check we're working with a similar version of pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a small timeseries air quality dataset from Oxford Street in London.\n",
    "\n",
    "This contains hourly-averaged readings of different gas and particulate \n",
    "species in the near-road environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = Path(\"../data/OxfordStreetAirQuality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an output folder, this will be used later on to save some data after we have processed it\n",
    "output_folder = Path(\"../data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a csv file\n",
    "df = pd.read_csv(data_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what we've got. Use df.info() or df.describe() to get some summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some rows where we we're missing some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As missing values don't tend to play nicely with the machine learning steps we might apply later, let's drop the rows with *any* missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is indexed by time, so let's make sure it has the right data type (in this case `datetime64`).\n",
    "\n",
    "E.g: ```\n",
    "df[COLUMN_NAME] = df[COLUMN_NAME].astype('datetime64')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the data type for the reading datetime\n",
    "df['ReadingDateTime'] = df['ReadingDateTime'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also use this as the index for the DataFrame, rather than just another column.\n",
    "\n",
    "Setting an index for a dataframe is a bit like setting names for the rows. You will then be able to select rows using these new indices. Operations like merging, concatenation, and pivoting also depend on the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index to the reading time\n",
    "df.set_index('ReadingDateTime', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table isn't in the most useful format for what we might want to do with it, for which we need the variables to be columns.\n",
    "\n",
    "Let's pivot it to obtain a table of `Value`s for each `Species` over `Time`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the table \n",
    "pivoted = pd.pivot_table(df, index=['ReadingDateTime'], columns=['Species'], values='Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that the data we've imported is aggregated on an hourly basis.\n",
    "\n",
    "Perhaps we're looking at longer term trends, and this level of detail is unecessary.\n",
    "\n",
    "We can `resample()` this data to a weekly(`W`)-`mean()`.  In other words, instead of hourly data, we get weekly data, with the values averaged over each week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a weekly mean\n",
    "weekly_mean = pivoted.resample('W', label='right').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For good measure, we can check what this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = weekly_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a flag for where one of the variables is beyond a certain threshold (you could do something simliar for e.g. data quality).\n",
    "\n",
    "In this case let's add a column called `'Hazardous'` which contains values which are `True` where the column `'NOX'` is above 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a data flag\n",
    "weekly_mean['Hazardous'] = weekly_mean['NOX'] > 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finished processing our data file, let's save it to our `output_folder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a processed data folder if there isn't one already\n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output this to a 'processed files' folder\n",
    "output_filepath = output_folder / 'WeeklyMeanAQ.csv'\n",
    "weekly_mean.to_csv(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a workflow we can use, let's combine the data processing steps above into a reusable function.\n",
    "\n",
    "A function is a block of code that performs a specific task. It is useful for organising your code, avoids repeated code, and can be resused in different parts of a large program. \n",
    "\n",
    "Example: \n",
    "\n",
    "```python\n",
    "def calc_quadratic(x):\n",
    "\n",
    "    y = x^2 + 2x + 5\n",
    "    \n",
    "    return y\n",
    "```\n",
    "\n",
    "\n",
    "To use the function:\n",
    "\n",
    "```python\n",
    "calc_quadratic(10)\n",
    "```\n",
    "\n",
    "Another example: \n",
    "\n",
    "```python\n",
    "def calc_quadratic(x, a, b, c):\n",
    "\n",
    "    y = a*x^2 + b*x + c\n",
    "    \n",
    "    return y\n",
    "```\n",
    "\n",
    "To use the function:\n",
    "```python\n",
    "calc_quadratic(10, 1, 2, 5)\n",
    "```\n",
    "\n",
    "A function is a self-contained piece of code. When you are writing your own function, check that the variables used inside the function are defined in relation to the arguments (in the above example, x, a, b, c are arguments of the function calc_quadratic). Calculations performed outside of the function will not affect what's inside the function.\n",
    "\n",
    "We've added the rough structure for you below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def process_csv_file(filepath, output_folder = Path(\"../data/processed/\"), fill_with=np.nan):\n",
    "    \"\"\"\n",
    "    Process a csv file so it's ready for exploratory data analysis.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    filepath\n",
    "        Path to the csv file to import.\n",
    "    output_folder \n",
    "        Path to the folder where you want the processed version to reside.\n",
    "    fill_with \n",
    "        Value to substitute for zero.\n",
    "        \n",
    "    Returns\n",
    "    --------\n",
    "    output_filepath\n",
    "        Path to the csv file which is output.\n",
    "        \n",
    "    Notes\n",
    "    --------\n",
    "    This function will convert data types and fill zeros with the specified value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 'filepath' is in the argument of this function\n",
    "    df = pd.read_csv(filepath) \n",
    "    \n",
    "    # remove rows with NAs\n",
    "    df.dropna(how='any', axis=0, inplace=True)\n",
    "    \n",
    "    df['ReadingDateTime'] = df['ReadingDateTime'].astype('datetime64')\n",
    "    \n",
    "    df.set_index('ReadingDateTime', inplace=True, drop=True)\n",
    "    \n",
    "    pivoted = pd.pivot_table(df, index=['ReadingDateTime'], columns=['Species'], values='Value')\n",
    "    \n",
    "    weekly_mean = pivoted.resample('W').mean()\n",
    "    \n",
    "    weekly_mean['Hazardous'] = weekly_mean['NOX'] > 50\n",
    "    \n",
    "    if not output_folder.exists():\n",
    "        output_folder.mkdir(parents=True)\n",
    "    \n",
    "    output_filepath = output_folder / 'WeeklyMeanAQ.csv'\n",
    "\n",
    "    weekly_mean.to_csv(output_filepath)\n",
    "    \n",
    "    # add the return value\n",
    "    return output_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy this function, and the libraries imported above into the separate file `processor.py` (Create a new text file and rename it as `processor.py`)\n",
    "\n",
    "Now when we want to use this function, we can import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_pipeline.processor import process_csv_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check back to see what arguments the function takes, you can use the inline help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(process_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_csv_file(data_filepath, \n",
    "                 output_folder =Path(\"../data/another_processed_data_folder/\"), \n",
    "                 fill_with=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing functions in separate files is useful for organising code in large programs. Functions used for processing data may be kept in one file, while functions used for importing data may be stored in another, for example. The main program then imports the required functions, remaining uncluttered. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
